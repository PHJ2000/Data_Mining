그래프 표현 학습(GRL: Graph Representation Learning)의 맥락에서 볼 때, 그래프 데이터는 노드($V$)와 엣지($E$)를 통해 개체와 그 관계를 포착하는 기본 구조입니다.

### 그래프 데이터의 구성 요소: 노드($V$)와 엣지($E$)

그래프($G$) 데이터는 **노드**($V$)를 개체(entities)로, **엣지**($E$)를 이 개체들 사이의 관계나 상호작용으로 표현합니다 ($G = V, E$).

*   **노드 ($V$, Vertices):**
    *   노드는 개체나 객체를 나타냅니다. 예를 들어, 소셜 네트워크에서 각 개인은 하나의 노드가 됩니다.
    *   노드는 이름, 나이, 위치 등과 같은 **속성(attributes)이나 속성값(properties)**을 가질 수 있습니다.
*   **엣지 ($E$, Edges or Links):**
    *   엣지는 노드 사이의 연결(connections)을 의미하며, 개체들 간의 관계 또는 상호작용을 나타냅니다.
    *   엣지는 방향성이 없을 수도 있고(Undirected), 방향성이 있을 수도 있습니다(Directed).
        *   **방향성이 없는 엣지**는 상호적인 관계(예: 페이스북의 상호 친구)를 의미하며 양방향 관계를 나타냅니다.
        *   **방향성이 있는 엣지**는 일방적인 관계(예: 인스타그램의 팔로워)를 나타냅니다.
    *   그래프 데이터의 예시로는 단백질-단백질 상호작용이나 단어 동시 발생 등이 있습니다.

### 그래프 표현 학습(GRL)의 맥락

그래프는 이미지나 텍스트와 달리 고정된 순서나 참조점이 없으며, 불규칙하고 복잡하게 연결되어 있기 때문에 기존의 정형화된 데이터와는 다르게 처리해야 하는 **복잡한 네트워크 구조**를 가집니다.

**GRL의 목표**는 이러한 고차원의 희소(sparse)한 그래프 구조 데이터(노드와 엣지로 이루어진)를 기계 학습 모델이 효율적으로 처리하고 학습할 수 있도록 저차원의 밀집(dense) 벡터(임베딩)로 효과적으로 인코딩하는 것입니다.

*   GRL은 원본 데이터를 추상화된 형태(특징 벡터 또는 임베딩)로 변환하는 표현 학습(Representation Learning) 기법의 한 종류입니다.
*   GRL은 노드 $u$를 임베딩 공간 $\mathbb{R}^d$로 매핑하며, **노드 간 임베딩의 유사성**은 네트워크 상에서의 노드 간 유사성을 나타냅니다.

### 엣지($E$) 정보를 활용한 GRL 메커니즘

그래프 신경망(GNN: Graph Neural Network)과 같은 GRL 기법들은 노드($V$)와 엣지($E$)가 정의하는 **연결 관계를 직접 활용**하여 임베딩을 학습합니다.

GNN은 일반적으로 두 단계의 과정을 통해 노드 임베딩을 계산하며, 이 과정에서 엣지가 중요한 역할을 합니다:

1.  **메시지 (Message):** 각 노드는 메시지를 생성하며, 이 메시지는 나중에 다른 노드(이웃 노드)에게 전송됩니다.
2.  **집계 (Aggregation):** 노드 $v$는 **자신의 이웃 노드($u \in N(v)$)로부터** 받은 메시지들을 취합(aggregate)하여 자신의 새로운 표현을 업데이트합니다.

이러한 메시지 교환 및 집계 과정은 엣지($E$)가 정의하는 이웃 관계를 통해 노드 정보가 네트워크 전체로 전파되도록 보장합니다. 예를 들어, GCN(Graph Convolutional Network)이나 GAT(Graph Attention Network) 같은 GNN 모델들은 메시지 변환과 이웃으로부터의 가중치 합산(집계)을 통해 엣지 정보를 활용합니다.

결론적으로, 그래프 데이터의 **노드($V$)는 임베딩될 개체**를 제공하고, **엣지($E$)는 GRL이 개체의 표현을 학습할 때 활용해야 하는 핵심적인 구조적 정보(관계)**를 제공합니다. GRL은 이 복잡한 $V$와 $E$의 상호작용을 압축하여 저차원 벡터로 변환하는 역할을 수행합니다.