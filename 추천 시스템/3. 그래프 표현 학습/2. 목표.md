그래프 표현 학습(GRL: Graph Representation Learning)은 고차원의 복잡한 그래프 데이터를 기계 학습에 적합한 형태로 변환하는 것을 목표로 합니다.

### GRL의 핵심 목표: 인코딩 및 차원 축소

그래프 표현 학습(GRL)의 궁극적인 목표는 **고차원의 희소한 그래프 구조 데이터**를 **저차원의 밀집된 벡터(임베딩)**로 효과적으로 인코딩하는 것입니다.

1.  **입력 데이터의 특성 (고차원 희소 그래프):**
    *   그래프($G$) 데이터는 개체를 노드($V$)로, 개체 간의 관계를 엣지($E$)로 나타냅니다.
    *   이러한 네트워크는 복잡하고 불규칙하며 복잡하게 연결되어 있습니다.
    *   그래프는 이미지의 규칙성이나 텍스트의 순서와 달리, 처리할 때 고정된 노드 순서나 참조점이 없기 때문에, 기존의 기계 학습 모델이 직접적으로 처리하기 어려운 **고차원 희소(sparse)한 구조**를 가집니다.

2.  **변환 과정 (표현 학습):**
    *   GRL은 기계 학습 시스템이 원시 데이터에서 특징 감지나 분류에 필요한 표현을 자동으로 발견하도록 하는 표현 학습(Representation Learning) 기법의 집합에 속합니다.
    *   GRL은 원본 데이터를 심층 학습 모델이 효율적으로 처리하고 학습할 수 있도록 **특징 벡터 또는 임베딩**과 같은 추상화된 형태로 변환합니다.

3.  **출력 임베딩의 역할 (저차원 밀집 벡터):**
    *   GRL은 노드 $u$ 또는 $v$를 임베딩 공간 $\mathbb{R}^d$로 매핑합니다.
    *   이렇게 생성된 **저차원의 밀집 벡터(임베딩)**는 개체의 속성과 네트워크 내 구조 정보를 압축적으로 담아냅니다.
    *   이 인코딩의 중요한 특징은 **노드 간 임베딩의 유사성**이 **네트워크 상에서의 노드 간 유사성**을 반영해야 한다는 점입니다.

### GRL의 방법론적 맥락

이러한 인코딩 목표를 달성하기 위해 GRL은 다양한 기법을 활용합니다:

*   **비지도 GRL:** 레이블 없이 노드 임베딩을 학습하며, 행렬 분해(Matrix factorization), 랜덤 워크(Random walk), 신경망(Neural network)과 같은 방법이 포함됩니다.
*   **준지도 GRL (GNN):** 부분적인 레이블을 사용하여 종단 간 학습(end-to-end learning)을 수행하는 그래프 신경망(GNN)을 포함합니다. GNN은 메시지와 집계(Aggregation)의 두 단계 과정을 통해 이웃 노드의 정보를 통합하여 노드 임베딩을 지속적으로 업데이트합니다.

결론적으로, GRL은 복잡한 네트워크 구조가 포함된 고차원의 데이터를 다루기 쉬운 **저차원 공간($\mathbb{R}^d$)으로 압축**하여, 후속 작업(예: 노드 분류 또는 링크 예측)에서 활용할 수 있는 의미론적 표현(Semantic representations)을 생성하는 것을 목적으로 합니다.