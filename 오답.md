트랜스포머의 어텐션 메커니즘에서, 디코더의 현재 상태를 나타내며 인코더의 어떤 정보에 주목할지를 결정하는 역할을 하는 것은 무엇입니까?

A.
쿼리 (Query) 벡터

B.
밸류 (Value) 행렬

C.
컨텍스트 (Context) 벡터

D.
키 (Key) 행렬


한 줄 요약

Q: “나(디코더 현재 상태)는 지금 이런 정보가 필요해. 인코더야, 누가 나랑 제일 잘 맞지?”

K: “난 이런 특징을 가진 토큰이야.”

V: “내가 가진 실제 내용은 이거야.”

Context: “Q가 선택한 결과로 모아온 요약 정보.”

그래서 답은 A. 쿼리 (Query) 벡터가 맞고,

---


트랜스포머의 인코더와 디코더 각 층에 공통적으로 포함되며, 어텐션 하위층(sub-layer) 다음에 위치하는 네트워크는 무엇입니까?

A.
순환 신경망 (RNN)

B.
컨볼루션 신경망 (CNN)

C.
오토인코더 (Autoencoder)

D.
멀티레이어 퍼셉트론 (MLP)


감으로 외우기 좋은 버전

어텐션: “어디를 볼지 정하는 블록”

MLP(FFN): “본 정보로 무슨 계산을 할지 처리하는 블록”

그래서

“어텐션 서브레이어 다음에 오는 네트워크”
라고 하면 바로 MLP (포지션-wise FFN) 떠올리면 됨.


---

자료에 따르면, 링크 예측(Link Prediction)의 응용 사례로 적절하지 않은 것은 무엇인가요?

A.
소셜 네트워크에서 친구 추천하기

B.
약물-약물 그래프에서 부작용 예측하기

C.
사용자-아이템 그래프에서 상품 추천하기

D.
온라인 광고에서 사용자 관심사 분류하기

시험용으로 한 줄로 기억하면:

링크 예측 = “두 노드 사이에 간선이 생길까?”
분류 문제 = “이 **노드/샘플의 타입(라벨)**이 뭐냐?”

그래프/링크 언급 없고 “분류”라고 나오면 일단 의심해도 된다.

---

1. 어디서 틀렸는지 (문항별 정리)
🔹 Q1 – 연관규칙

1(b) 2-itemset support / frequent

{m,b} support를 1로 썼는데 실제는 3.

그래서 frequent 2-itemset에서 {m,b}가 빠짐.

👉 원인: support 세는 과정에서 놓친 basket(B5) 있음.
(개념 문제 X, 그냥 “카운트 실수”)

## 이건 실수 맞았음


---

🔹 Q4 – Grubbs’ Test

(b) 표준편차 s

9라고 적고 “계산법 모르겠음” → 공식 자체를 확실히 안 잡은 상태.

(c) G = 80.6 / 9

분자는 잘 잡았는데,

분모로 표준편차 s 대신 n 비슷한 숫자를 넣어버림.

(d) 결론

G와 G_crit 비교 후 “이상치냐/아니냐” 판단을 못 함.

👉 원인

표준편차/분산 공식이 몸에 안 배어 있음.

Grubbs 공식을 “대충 비율” 정도로 기억하고 있어서 **정확한 형태 (max편차 / s)**를 못 쓴 상태.

검정 절차:
G > Gcrit 이면 이상치 있음 → outlier로 본다
이 로직을 아직 패턴으로 못 외운 상태.

## 표준 편차 공식을 몰랐고, 이걸 모르니 공식도 제대로 못함, 귀무가설, 대립가설 제시가 애매했음
## 그러니깐 귀무가설이 없을 거다. 대립가설이 가장 극단값이 이상값이다. 이걸 정확히 몰랐음


---

🔹 Q5 – Mahalanobis

(b) D² 계산

(𝑥−𝜇)=(6,6)
(x−μ)=(6,6) 까지는 맞았는데,

(𝑥−𝜇)𝑇Σ−1(𝑥−𝜇)(x−μ)TΣ−1
(x−μ) 숫자까지 못 밀어붙임.

(c)

“기준보다 크면 이상치” 개념은 맞는데,

실제 D² 값을 못 구해서 최종 판정도 흐릿해짐.

👉 원인

수식 구조는 이해했지만
“대각선 Σ⁻¹이면 그냥 
(𝑥1−𝜇1)2𝜎12+...σ12(x1−μ1)2+...” 
같은 계산 패턴을 아직 익숙하게 안 다룸.

“행렬 곱 → 스칼라” 계산을 끝까지 안 밀고 멈춤.

## 행렬곱을 제대로 못한게 컷음, 기준보다 크면 이상치도 라는 개념도 약간 그럴거 같아서 찍은거에 가까워

---

🔹 Q6 – k-NN outlier score

(a)

P1에 대해서는 거리들을 잘 썼는데,

나머지는 “복잡하다” 수준에서 멈춤.

(b)

“2번째로 가까운 친구까지의 거리”라는 개념은 맞게 이해.

근데 P1의 2-NN을 sqrt(0.13)라고 쓴 건 틀림
(실제로는 P2, P3 둘 다 sqrt(0.05)라 2-NN도 sqrt(0.05)).

(c)

“평균에서 먼 친구” 같은 말로 뭉뚱그려서 넘김.

실제로는 k-NN score가 제일 큰 P4를 찍어줘야 함.

👉 원인

거리 자체는 잘 계산하는데,

끝까지 정렬해서 k번째 이웃 찾는 작업에서 귀찮아서 멈춘 느낌.

“제일 먼 점이 이상치겠지”라는 직관은 맞는데,
실제 수치 비교까지 안 해봄 → 정답 확신을 못 잡음.

## 이거 2개의 이웃을 가까운 두개 이웃으로 안본게 문제였음, 그리고 제일 먼 친구인 스코어가 제일 큰거 찍을 생각을 못함 이젠 암


---

🔹 Q7 – DBSCAN

“모르겠다”로 전체 패스.

👉 원인

DBSCAN core/border/noise 정의는 머리에 있을 수 있는데,
ε-이웃을 실제로 세어본 경험이 거의 없는 상태.

처음 보는 유형처럼 느껴져서 아예 손을 안 댄 케이스.

## 자기자신도 이웃에 포함해서 구해버리면 됬던 것
## 가장 가까운 이웃들을 기준으로 거리 계산 하는 것도 몰랐음

정의:

core point: |Nε(p)| ≥ minPts

border point: core에 이웃으로 연결은 되지만, 자기 이웃 수는 minPts 미만

noise: 둘 다 아님

## 문제를 포기한게 가장 큰 문제였음


---


Q8 – Item-based Collaborative Filtering

(a)

정답은 𝑟^𝑥𝐷=6.4/1.4≈4.57r^xD
	​

=6.4/1.4≈4.57

네 답: 12 (분자합만 쓴 값에 가까움)

(b)

정답은 A, C만 쓴 
𝑟^𝑥𝐷≈6.1/1.3≈4.69r^xD
	​

≈6.1/1.3≈4.69

네 답: 9 (역시 분자 쪽 값만 쓰고 분모 없이 끝낸 느낌)

👉 원인

weighted average 형태:

𝑟^=∑𝑠𝑖𝑗𝑟𝑥𝑗∑∣𝑠𝑖𝑗∣r^=∑∣sij∣∑sij​rxj
	​

	​


에서 분자만 계산하고 분모 나누기를 빼먹는 습관적 실수.

공식 개념은 알고 있었는데, 실제 계산 단계에서 마무리 규칙이 빠진 것.

## 사실 분모쪽에 있는 시그마를 빼먹어서 생긴 문제임

---

🔹 Q12 – Attention

(a)

정답: 
𝑠1=1,𝑠2=1s1​=1,s2=1

네 답: 2, 2 → 점곱에서 잘못 곱함.

(b)

softmax([s1, s2]) 계산을 못 해서 패스.

(c)

“2번만 구하면 할 수 있을 것 같다” → 수식 이해는 되어 있고,

softmax output만 막혔던 상태.

👉 원인

Q·K 점곱부터 부호/곱셈이 꼬임.

softmax를 “어떻게 생긴 함수인지”는 아는데,
실제 숫자 넣어서 계산해 본 경험이 부족:

둘이 같으면 0.5, 0.5 같은 단순 케이스도 패턴으로 못 떠올림.

## 행렬곱이 너무 어려웠음

---


🔹 Q13 – FFN (행렬 곱 + ReLU)

(a) f₁

정답: f₁ = [-3, 3, -1]

네 답: [-2, 2, 1] → 곱셈/덧셈에서 다수 항목 틀림.

(b) ReLU

정답: [0, 3, 0]

네 답: [0, 2, 1] → (a)가 틀렸으니 연쇄로 같이 틀림.

(c) 최종 output

정답: -3

네 답: 6 → 앞 단계가 다 틀어져서 결과도 엉망.

👉 원인

(1×2)×(2×3) 행렬 곱에서

“각 자리에서 무엇을 곱하고 더해야 하는지”가 아직 자동화 안 되어 있음.

ReLU는 알고 있지만, 입력 값 자체가 틀리니 출력도 같이 깨짐.

한 번 틀린 걸로 계속 밀고 가서 최종 값까지 다 어긋난 케이스.

## 행렬곱을 제대로 풀지 못함


---


## 고난이도 퀴즈


---

아이템 쌍의 빈도를 메모리에서 계산하는 두 가지 접근법, '삼각 행렬(Triangular Matrix)'과 '트리플(Triples)' 방식에 대한 설명으로 올바르지 않은 것은 무엇입니까?

A.
트리플 방식은 실제로 등장한 아이템 쌍에 대해서만 메모리를 사용한다.

B.
삼각 행렬 방식이 트리플 방식보다 항상 더 적은 메모리를 사용한다.
정답
실제로 발생하는 쌍의 수가 전체 가능한 쌍의 수의 1/3보다 적을 경우, 트리플 방식이 더 적은 메모리를 사용합니다. 따라서 삼각 행렬 방식이 '항상' 효율적인 것은 아닙니다.

C.
삼각 행렬 방식은 모든 가능한 아이템 쌍에 대해 공간을 할당한다.

D.
삼각 행렬은 아이템 쌍당 약 4바이트, 트리플은 약 12바이트를 사용한다.
오답
자료에 따르면 삼각 행렬은 카운트 저장을 위해 4바이트, 트리플은 두 아이템 ID와 카운트 저장을 위해 12바이트를 사용한다고 언급됩니다.


👉 보완 방법:

“항상(always), 반드시, only” 같은 단어가 보이면
→ 일단 의심부터 하고 반례가 있는지 생각해볼 것.

Triangular vs Triples는 시험용 문장으로 딱 2줄만 정리:

“Triangular: dense, 모두 저장, 4byte”

“Triples: sparse, 등장하는 것만, 12byte, 실제 pair가 적으면 유리”

---

그래프에서 커뮤니티를 찾기 위해 연관 규칙 마이닝을 적용할 때, 이는 어떤 종류의 부분 그래프를 찾는 것과 유사합니까?

A.
해밀턴 경로 (Hamiltonian Path)

B.
최소 신장 트리 (Minimum Spanning Tree)
오답
최소 신장 트리는 모든 노드를 최소 비용으로 연결하는 것을 목표로 하며, 노드들이 서로 조밀하게 연결된 커뮤니티 탐색과는 다릅니다.

C.
클릭 (Clique)

D.
완전 이분 부분 그래프 (K s,t)
정답
소스 자료에 따르면, s개의 노드(장바구니)가 공통적으로 t개의 다른 노드(아이템)를 가리키는 구조를 찾는 것이며, 이는 크기가 s, t인 완전 이분 부분 그래프(K 
s,t)를 찾는 것과 같습니다.


이건 그냥 매핑만 외우면 된다:

거래(basket) ↔ 한쪽 노드 집합

아이템 ↔ 다른 쪽 노드 집합

⇒ “여러 basket이 동시에 여러 item을 공유” = 완전 이분 그래프

Clique는 한 파트 안에서 완전 연결이고, 여기서는 basket과 item이 양쪽 집합이라 다르다.

---

A-Priori와 같은 연관 규칙 마이닝 알고리즘에서 디스크에 저장된 대용량 데이터를 처리할 때, 주된 성능 측정 기준(비용)은 무엇입니까?

A.
주 메모리의 전체 크기
오답
주 메모리 크기는 알고리즘의 실행 가능 여부를 결정하는 제약 조건이지만, 실행 중 성능을 측정하는 직접적인 비용 척도는 아닙니다.

B.
알고리즘이 전체 데이터를 읽는 횟수 (Pass의 수)
정답
디스크 I/O는 CPU 연산보다 훨씬 느리기 때문에, 전체 데이터를 몇 번이나 스캔하는지가 알고리즘의 전체 실행 시간을 좌우하는 가장 중요한 비용 척도가 됩니다.

C.
알고리즘이 사용하는 총 CPU 시간

D.
생성되는 최종 연관 규칙의 개수

디스크 기반/스트리밍 알고리즘 나오면:

“Pass 수 = 비용” 이라고 자동으로 떠오르게 연습.

“메모리 크기”는 제약 조건이고, “pass 수”가 실제 시간 비용.

---

그럽스 테스트(Grubbs' Test)가 이상치 탐지에 가장 적절하게 사용되는 상황은 언제입니까?

A.
한 번의 테스트로 여러 개의 이상치를 동시에 탐지하고자 할 때

B.
데이터가 정규분포를 따른다고 가정하는 일변량 데이터를 분석할 때
정답
이는 그럽스 테스트의 핵심 가정과 적용 대상(일변량, 정규분포)에 정확히 부합합니다.

C.
데이터셋에 여러 다른 분포가 섞여 있는 것으로 알려져 있을 때

D.
분포를 알 수 없는 다변량 데이터를 분석할 때
오답
그럽스 테스트는 정규분포를 따르는 '일변량' 데이터에 사용됩니다.


👉 키워드 고정:

Grubbs = univariate + normal + (대부분) single outlier

여러 개 이상치는 일반적으로 반복 적용하거나 다른 방법 사용

---

본문에 설명된 가능도 기반(Likelihood-based) 접근법에서, 데이터 포인트가 이상치로 식별되는 과정은 무엇입니까?

A.
해당 포인트를 다수 집합 'M'에서 이상치 집합 'A'로 옮겼을 때, 전체 로그 가능도의 감소량이 특정 임계값보다 클 때
정답
본문에서는 LL 
t
​
 (D)−LL 
t+1
​
 (D)가 특정 임계값보다 크면, 즉 해당 포인트를 제거했을 때 가능도 '손실'이 적으면(혹은 설명력이 크게 떨어지지 않으면) 이상치로 판단합니다. 이 설명은 그 개념을 반영합니다.

B.
해당 포인트가 균등 분포를 따르는 이상치 분포 'A' 하에서 계산된 확률이 특정 값 이상일 때

C.
해당 포인트를 이상치 집합 'A'로 옮겼을 때 전체 데이터셋의 로그 가능도(log likelihood)가 크게 증가할 때
오답
반대입니다. 정상 집합에서 이상치를 제거하면 모델이 데이터를 더 잘 설명하게 되므로 가능도가 증가해야 하지만, 본문에서는 가능도의 차이를 계산합니다.

D.
해당 포인트의 마할라노비스 거리가 미리 정의된 임계값을 초과할 때


보완:

likelihood 기반 문제에서는

“이상치는 제거하면 모델이 좋아진다”

라는 직관을 머릿속에 먼저 박아두고 문항 읽기.

---

실제 이상치 여부를 알려주는 레이블이 있을 때, 거짓 양성 비율(FPR, False Positive Rate)과 동일한 의미로 언급된 평가 지표는 무엇입니까?

A.
정밀도 (Precision)

B.
정보 획득량 (Information gain)

C.
재현율 (Recall)
오답
재현율은 실제 이상치 중에서 모델이 이상치로 올바르게 예측한 비율을 나타냅니다.

D.
오탐지율 (False alarm rate)
정답
본문에서는 FPR이 'false alarm rate'로도 알려져 있다고 명시하고 있습니다.


보완:

혼동행렬 간단히 그려서 외우는 게 제일 빠름:

	예측 이상치	예측 정상
실제 이상치	TP	FN
실제 정상	FP	TN

Recall = TP / (TP + FN)

FPR = FP / (FP + TN) = False alarm rate

이걸 한 번 손으로 적고, “false alarm = 정상인데 알람 울린 경우(FP)”로 연결해두면 안 까먹는다.

---

트랜스포머의 인코더와 디코더 각 층에서 어텐션 하위 계층(sub-layer) 외에 추가적으로 사용되며, 각 위치마다 개별적이고 동일하게 적용되는 네트워크는 무엇입니까?

A.
다층 퍼셉트론 (Multi Layer Perceptron)
오답
피드-포워드 네트워크가 MLP의 한 형태이긴 하지만, 본문에서는 'Position-wise Feed-Forward Network'라는 구체적인 용어를 사용하며 그 역할을 설명하고 있습니다.

B.
순환 신경망 (Recurrent Neural Network)

C.
위치별 피드-포워드 네트워크 (Position-wise Feed-Forward Network)
정답
이 네트워크는 두 개의 선형 변환과 ReLU 활성화 함수로 구성되며, 어텐션을 통해 얻은 정보를 각 위치별로 추가 처리하는 역할을 합니다.

D.
스케일드 닷-프로덕트 어텐션 (Scaled Dot-Product Attention)


보완:

“Transformer = Multi-head Attention + Position-wise FFN”
이 두 키워드를 세트로 외워라.

시험에서 굳이 용어를 물으면 반드시 ‘Position-wise FFN’ 를 골라야 함.

---

협업 필터링(Collaborative Filtering)에서 k-최근접 이웃(k-nearest neighbors)을 사용하여 사용자 x의 아이템 i에 대한 평점을 예측할 때, N(i;x)는 무엇을 의미합니까?

A.
사용자 x가 평가한 모든 아이템 중에서 가장 높은 평점을 받은 아이템 집합입니다.

B.
사용자 x와 가장 유사한 k명의 사용자 집합입니다.
오답
이는 사용자 기반 협업 필터링에서 사용되는 개념이며, N(i;x)는 아이템 기반 접근 방식에서의 이웃을 의미합니다.

C.
전체 아이템 중에서 인기도가 가장 높은 k개의 아이템 집합입니다.

D.
아이템 i와 가장 유사하면서 사용자 x가 평가한 아이템들의 집합입니다.
정답
아이템 기반 협업 필터링에서는 대상 아이템(i)과 유사한 다른 아이템들에 대한 사용자(x)의 평점을 기반으로 예측을 수행합니다.


👉 보완:

CF 파트를 이렇게 표 하나로 정리:

user-based: “비슷한 사용자들(이웃) → 그들이 평가한 아이템”

item-based: “비슷한 아이템들(이웃) → 그 아이템에 대해 x가 준 평점”

---

Collective Matrix Factorization(CMF)이 기존의 행렬 분해와 구별되는 가장 큰 특징은 무엇입니까?

A.
SVD 대신 경사 하강법(gradient descent)을 사용하여 최적화를 수행합니다.
오답
경사 하강법은 희소 행렬에 대한 일반적인 행렬 분해에서도 사용될 수 있는 최적화 기법으로, CMF만의 고유한 특징은 아닙니다.

B.
반드시 그래프 구조의 데이터에만 적용할 수 있습니다.

C.
오직 사용자 정보 행렬만을 분해하여 잠재 요인을 추출합니다.

D.
하나 이상의 행렬을 동시에 처리하여 공동으로 저차원 인수를 얻습니다.
정답
CMF는 여러 정보 소스(행렬)를 함께 분해하여 공유되는 잠재 요인을 학습함으로써 성능을 향상시키는 것을 목표로 합니다.


👉 보완:

한 줄 요약 외우기:

“CMF = 여러 행렬 동시에 분해해서 공유되는 latent factor 뽑는 것”

---

그래프 표현 학습(GRL)에서, 두 노드의 임베딩 벡터 간의 유사도는 무엇을 의미하는 경향이 있습니까?

A.
두 노드가 가진 속성(attribute)의 개수가 동일함을 의미합니다.

B.
원래 그래프 네트워크 상에서 두 노드가 서로 유사한 위치나 역할을 가짐을 의미합니다.
정답
GRL의 목표는 네트워크에서의 유사성(예: 이웃이 비슷하거나, 구조적으로 비슷한 위치에 있는 등)을 임베딩 공간에서의 거리나 유사성으로 보존하는 것입니다.

C.
두 노드가 항상 직접적인 엣지(edge)로 연결되어 있음을 의미합니다.
오답
직접 연결된 노드들은 유사할 가능성이 높지만, 직접 연결되지 않았더라도 공통의 이웃을 많이 갖는 등 구조적으로 유사하면 임베딩이 가까울 수 있습니다.

D.
두 노드의 차수(degree), 즉 연결된 엣지의 수가 정확히 같음을 의미합니다.


👉 핵심:

임베딩이 가깝다 =

이웃 구조가 비슷하거나,

같은 커뮤니티/역할(허브, 브리지 등)을 갖는 노드일 가능성이 크다.

직접 edge가 있어야만 가까운 건 아니다.


---

자료에 언급된 비지도(unsupervised) GRL 방법이 아닌 것은 무엇입니까?

A.
Neural network

B.
Random walk

C.
Graph Neural Network (GNN)
정답
자료에서는 GNN을 자기지도(self-supervised) 학습 방식으로 분류하고 있으며, 일부 레이블을 사용하는 준지도(semi-supervised) 학습에도 활용됩니다.

D.
Matrix factorization
오답
행렬 분해는 인접 행렬 등을 분해하여 노드 임베딩을 학습하는 대표적인 비지도 GRL 방법입니다.


👉 강의 기준으로는:

Random walk, MF 등: 비지도 대표.

GNN: self-supervised / semi-supervised가 기본 세팅으로 소개됨.

---

추천 시스템의 'Key Problems' 중, 알려진 평점으로부터 알려지지 않은 평점을 추정하는 문제에 해당하는 접근법이 아닌 것은 무엇입니까?

A.
Content-based filtering

B.
Latent factor based models

C.
Collaborative filtering
오답
협업 필터링은 다른 사용자의 평점 패턴을 기반으로 알려지지 않은 평점을 추정하는 대표적인 방법입니다.

D.
Explicit or Implicit feedback gathering
정답
이는 알려진 평점을 '수집'하는 단계에 대한 설명이며, 수집된 데이터를 바탕으로 알려지지 않은 평점을 '추정'하는 단계와는 구분됩니다.


👉 정리:

추정(estimation) 방법:

Content-based

Collaborative filtering

Latent factor models

수집(gathering):

Explicit / implicit feedback

→ 수집은 데이터 모으는 단계,
CF/latent factor는 추정하는 단계.


---

물리적인 세상과 온라인 세상의 상품 진열 방식에 대한 'Long-Tail' 이론의 설명으로 가장 적절한 것은 무엇입니까?

A.
물리적인 세상은 오직 가장 인기 있는(most popular) 상품들만 진열하는 경향이 있습니다.
정답
공간과 재고 비용 때문에, 물리적 상점은 잘 팔리는 소수의 인기 상품에 집중할 수밖에 없습니다.

B.
온라인 세상은 물리적 제약이 없어 가장 인기 있는 상품들만 진열하는 것이 가능합니다.
오답
반대로, 물리적인 세상이 공간 제약 때문에 인기 상품 위주로 진열하는 경향이 있습니다.

C.
온라인 세상에서는 모든 고객에게 동일한 상품 목록을 보여주는 것이 일반적입니다.

D.
Long-Tail 이론은 오직 비인기 상품들만을 판매해야 성공할 수 있다는 전략입니다.


👉 포인트:

오프라인: 진열 공간 / 재고비 제한 → head(인기상품) 중심

온라인: 공간 제약 거의 없음 → tail까지 다루는 게 가능/유리

---
